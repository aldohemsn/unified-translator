# Video Translation Service - Logic Breakdown

## ğŸ“‹ Executive Summary

The **Video Strategy** in the Unified Translator framework is specifically designed for translating **subtitles, scripts, and video transcripts**. It addresses unique challenges in video translation:

- **Fragmented context** (dialogues jump between speakers/scenes)
- **Transcription errors** (ASR mistakes, homophones)
- **Translation artifacts** ("Translationese" - awkward literal translations)
- **VO vs. OS text** (Voice-Over needs fluidity, On-Screen needs conciseness)

---

## ğŸ—ï¸ Architecture Overview

### System Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Video Translation Pipeline                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  1. INPUT: TSV file (ID, Source, Target)                        â”‚
â”‚     â†“                                                            â”‚
â”‚  2. SETUP PHASE:                                                 â”‚
â”‚     â”œâ”€â†’ Compress Full Transcript â†’ Scene Summary (500 chars)    â”‚
â”‚     â””â”€â†’ Generate Style Guide â†’ VO/OS Guidelines                 â”‚
â”‚     â†“                                                            â”‚
â”‚  3. BATCH PROCESSING:                                            â”‚
â”‚     â”œâ”€â†’ Build Context Window (History + Scene Summary)          â”‚
â”‚     â”œâ”€â†’ Apply Blacklist (Translationese Prevention)             â”‚
â”‚     â”œâ”€â†’ Transcription Audit (Flag ASR errors)                   â”‚
â”‚     â”œâ”€â†’ Translation/Proofreading (LLM Call)                      â”‚
â”‚     â””â”€â†’ VO/OS Separation (Comments Field)                       â”‚
â”‚     â†“                                                            â”‚
â”‚  4. OUTPUT: Enhanced TSV (ID, Source, Target, Comments)          â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ” Core Components Deep Dive

### 1. **Setup Phase** (`setup()` method)

The setup phase runs **once before processing** to prepare contextual aids:

#### A. Compressed Context Generation

**Problem:** Full transcripts can be 10,000+ characters, consuming excessive tokens.

**Solution:** Compress the first 500 lines (5000 chars) into a structured 500-character summary.

**Implementation:**
```python
def _generate_compressed_context(self, full_text: str):
    compress_prompt = f"""ä¸ºä»¥ä¸‹è§†é¢‘å­—å¹•ç”Ÿæˆã€åœºæ™¯æ‘˜è¦ã€‘ï¼Œç”¨äºæŒ‡å¯¼ç¿»è¯‘ã€‚

    è¯·åŒ…å«ï¼š
    1. **ä¸»é¢˜**: è§†é¢‘åœ¨è®²ä»€ä¹ˆï¼ˆä¸€å¥è¯ï¼‰
    2. **è¯´è¯äºº**: æœ‰å“ªäº›è§’è‰²/èº«ä»½ï¼ˆå¦‚ï¼šä¸»æŒäººã€å˜‰å®¾Aã€æ—ç™½ï¼‰
    3. **è¯­å¢ƒ**: æ­£å¼/å£è¯­ï¼Œæ–°é—»/æ•™ç¨‹/å‰§æƒ…/é‡‡è®¿
    4. **å…³é”®æœ¯è¯­**: ä¸“æœ‰åè¯ã€äººåã€å“ç‰Œåï¼ˆåˆ—å‡º 5-10 ä¸ªï¼‰
    5. **ç‰¹æ®Šæ³¨æ„**: ä»»ä½•ç¿»è¯‘æ—¶éœ€è¦æ³¨æ„çš„ç‚¹

    å­—å¹•åŸæ–‡ï¼ˆå‰ 5000 å­—ç¬¦ï¼‰ï¼š
    {full_text[:5000]}
    """
    
    response = llm.generate(compress_prompt, model='gemini-2.5-flash-lite')
    self.transcript_context = response.strip()  # Stored for batch processing
```

**Example Output:**
```
ä¸»é¢˜ï¼šç§‘æŠ€äº§å“å‘å¸ƒä¼š
è¯´è¯äººï¼šä¸»æŒäººã€CEOã€æŠ€æœ¯æ¼”ç¤ºè€…
è¯­å¢ƒï¼šæ­£å¼å‘å¸ƒä¼šï¼Œå¶æœ‰è½»æ¾äº’åŠ¨
å…³é”®æœ¯è¯­ï¼šAIèŠ¯ç‰‡ã€ç¥ç»å¼•æ“ã€ProMotionã€MagSafeã€iOS 18
ç‰¹æ®Šæ³¨æ„ï¼šä¿æŒå“ç‰Œåè‹±æ–‡ï¼ŒæŠ€æœ¯æœ¯è¯­éœ€ä¸“ä¸šå¯¹åº”
```

**Token Savings:** ~84% reduction (5000 â†’ 500 chars)

#### B. Style Guide Generation

**Purpose:** Establish translation conventions **before** processing begins.

**Implementation:**
```python
def _generate_detailed_style_guide(self, llm, text):
    prompt = f"""
    You are a Senior Localization Architect for Video Content.
    Task: Create a "Best Efficient Style Guide".
    
    Sections Required:
    1. **Project Context**: Topic, Vibe (e.g., Casual YouTube vs. Formal Doc).
    2. **Stylistic Protocols**:
       - **Voice-Over (VO)**: Guidelines for spoken narrative (fluidity, breath).
       - **On-Screen Text (OS)**: Guidelines for titles/labels (conciseness, nominal style).
    3. **Formatting**: Rules for numbers, punctuation in subtitles.
    
    Source Text Snippet: {text[:5000]}
    """
    
    self.style_guide = llm.generate(prompt, model='gemini-2.5-flash')
```

**Example Output:**
```
**Project Context:**
- Topic: Tech product launch event
- Vibe: Professional yet engaging, mix of scripted and spontaneous

**Stylistic Protocols:**
- VO: Natural flow, complete sentences, allow reordering for Chinese grammar
- OS: Terse, keyword-focused, preserve alignment with visuals

**Formatting:**
- Numbers: Use Arabic numerals for specs (8GB), Chinese for narrative (å…«ä¸ª)
- Punctuation: Minimize in OS, natural in VO
```

---

### 2. **Batch Processing Loop** (`process_batch()` method)

This is the **main translation engine**, called repeatedly by the Processor for each batch of rows.

#### Configuration
```yaml
# From config.yaml
video:
  batch_size: 30            # Large batches (video has high context continuity)
  context_window:
    before: 5               # Include 5 previous rows for context
    after: 0                # No lookahead needed
  inject_full_context: true # Use compressed scene summary
```

#### Processing Steps

**Step 1: Format Batch Data**
```python
formatted_batch = []
for r in batch_rows:
    formatted_batch.append({
        'ID': r.get('ID'),
        'English': r.get('Source'),
        'Chinese': r.get('Target', '')  # Empty if translation mode
    })
```

**Step 2: Build History Context**
```python
# Get last 5 processed rows for sliding window
history_snippet = json.dumps([
    {'English': r['Source'], 'Chinese': r['Target']}
    for r in history_rows[-5:]
], ensure_ascii=False)
```

**Step 3: Construct Translationese Blacklist**
```python
blacklist_terms = ['è¿›è¡Œ', 'é€šè¿‡', 'æ—¨åœ¨', 'å®ƒ', 'ä»»ä½•']  # From config

blacklist_instruction = """
**NEGATIVE CONSTRAINTS (Translationese Blacklist)**:
- Do NOT use "è¿›è¡Œ" (avoid "è¿›è¡Œè®¨è®º", use "è®¨è®º")
- Do NOT use "é€šè¿‡" (avoid "é€šè¿‡...æ–¹å¼")
- Do NOT use "æ—¨åœ¨" (overly formal)
- Do NOT use "å®ƒ" (Chinese often omits pronouns)
- Do NOT use "ä»»ä½•" (use specific terms)
"""
```

**Step 4: Build Comprehensive Prompt**
```python
prompt = f"""
[STYLE GUIDE]
{self.style_guide}  # Generated in setup

{blacklist_instruction}

[SCENE SUMMARY (Compressed Context)]
{self.transcript_context}  # Generated in setup

[PREVIOUS CONTEXT]
{history_snippet}  # Last 5 rows

[TASK]
1. **Transcription Audit**: Check 'English' source for typos, ASR errors (homophones), or wrong names.
   - Protocol: If error found, PREPEND "âš ï¸ [TRANSCRIPTION FLAG]: <Note>" to 'Comments'.
2. **Translation/Proofreading**:
   - If 'Chinese' is empty: Translate the English source.
   - If 'Chinese' exists: Proofread and improve the existing translation.
   - Determine if segment is VO (Spoken) or OS (Text).
   - Apply appropriate style (VO=Fluid, OS=Concise).

[INPUT DATA]
{json.dumps(formatted_batch, indent=2, ensure_ascii=False)}

[OUTPUT FORMAT]
JSON Array of {{ "ID": "...", "Chinese_Proofread": "...", "Comments": "..." }}
"""
```

**Step 5: LLM Call**
```python
response = llm_client.generate(
    prompt,
    model='gemini-2.5-pro',  # High-quality model for translation
    response_mime_type='application/json'
)
results = json.loads(response)
```

**Step 6: Process Results**
```python
for row in batch_rows:
    res = result_map.get(row['ID'], {})
    
    output.append({
        'ID': row['ID'],
        'Source': row['Source'],
        'Target': res.get('Chinese_Proofread', row.get('Target', '')),
        'Comments': res.get('Comments', '')  # Contains flags, VO/OS tags
    })
```

---

## ğŸ¯ Key Features Explained

### Feature 1: **Transcription Audit**

**Why:** ASR (Automatic Speech Recognition) often produces homophones or mishears names.

**Example:**
- **Source (ASR Output):** "pay an RMB"
- **Actual Speech:** "pay an arm and a leg"

**Detection Logic:**
```python
# LLM is instructed to flag suspicious transcriptions:
"""
1. **Transcription Audit**: Check 'English' source for typos, ASR errors (homophones), or wrong names.
   - Protocol: If error found, PREPEND "âš ï¸ [TRANSCRIPTION FLAG]: <Note>" to 'Comments'.
"""
```

**Output:**
```json
{
  "ID": "42",
  "Chinese_Proofread": "ä»˜å‡ºå·¨å¤§ä»£ä»·",
  "Comments": "âš ï¸ [TRANSCRIPTION FLAG]: Suspected 'pay an RMB' should be 'pay an arm and a leg'"
}
```

---

### Feature 2: **Translationese Blacklist**

**Problem:** Direct translation often produces awkward Chinese (ç¿»è¯‘è…” - "Translationese").

**Bad Example:**
- EN: "Through discussion, we achieve progress"
- BAD CN: "é€šè¿‡è®¨è®ºï¼Œæˆ‘ä»¬è¿›è¡Œè¿›æ­¥" (literally "through discussion, we perform progress")
- GOOD CN: "è®¨è®ºåï¼Œæˆ‘ä»¬å–å¾—è¿›å±•" ("after discussion, we achieve progress")

**Implementation:**
```yaml
# config.yaml
blacklist_terms:
  - "è¿›è¡Œ"  # Generic verb ("perform/carry out")
  - "é€šè¿‡"  # "Through" (overused preposition)
  - "æ—¨åœ¨"  # "Aims to" (overly formal)
  - "å®ƒ"    # "It" (Chinese omits pronouns naturally)
  - "ä»»ä½•"  # "Any" (prefer specific terms)
```

**LLM Instruction:**
```
**NEGATIVE CONSTRAINTS (Translationese Blacklist)**:
- Do NOT use "è¿›è¡Œ" (avoid "è¿›è¡Œè®¨è®º", use "è®¨è®º")
- Do NOT use "é€šè¿‡" (avoid "é€šè¿‡...æ–¹å¼")
...
```

---

### Feature 3: **VO/OS Separation**

**Concept:**
- **VO (Voice-Over):** Spoken dialogue/narration â†’ needs natural flow
- **OS (On-Screen):** Titles, labels, UI text â†’ needs conciseness

**Translation Approach:**

| Type | English | VO Translation | OS Translation |
|------|---------|---------------|----------------|
| VO | "Welcome to our comprehensive product showcase" | "æ¬¢è¿æ¥åˆ°æˆ‘ä»¬çš„äº§å“å±•ç¤ºä¼š" (natural) | âŒ (too long for subtitle) |
| OS | "Click here to learn more" | âŒ (not spoken) | "ç‚¹å‡»äº†è§£è¯¦æƒ…" (terse) |

**Detection:**
```python
# LLM is instructed to:
"""
2. **Translation/Proofreading**:
   - Determine if segment is VO (Spoken) or OS (Text).
   - Apply appropriate style (VO=Fluid, OS=Concise).
"""
```

**Output:**
```json
{
  "ID": "10",
  "Chinese_Proofread": "ç‚¹å‡»äº†è§£è¯¦æƒ…",
  "Comments": "OS (On-Screen Text) - kept concise for visual alignment"
}
```

---

### Feature 4: **Context Compression**

**Problem:** Video transcripts are long, but injecting full text wastes tokens.

**Before (Naive Approach):**
```python
# Inject first 3000 characters raw
prompt = f"""
[FULL TRANSCRIPT]
{' '.join(all_rows[:500])}  # ~3000 chars

[CURRENT BATCH]
{current_batch}
"""
```
- **Token Cost:** ~750 tokens per batch
- **Context Quality:** Lots of noise (repetition, filler words)

**After (Compressed Approach):**
```python
# Compress to structured 500-char summary
prompt = f"""
[SCENE SUMMARY]
ä¸»é¢˜ï¼šç§‘æŠ€äº§å“å‘å¸ƒä¼š
è¯´è¯äººï¼šä¸»æŒäººã€CEO
å…³é”®æœ¯è¯­ï¼šAIèŠ¯ç‰‡ã€ProMotion
"""
```
- **Token Cost:** ~125 tokens per batch (84% reduction)
- **Context Quality:** High (curated, structured)

---

## ğŸ› ï¸ Model Selection Strategy

The Video Strategy uses **different models for different stages** to optimize cost/quality:

```yaml
models:
  context_compression: "gemini-2.5-flash-lite"  # Fast compression
  style_guide: "gemini-2.5-flash"              # Medium quality
  translation: "gemini-2.5-pro"                # High quality â­
```

**Rationale:**
- **Setup (1x):** Use cheaper models (flash-lite/flash) since it runs once
- **Translation (Nx):** Use premium model (pro) since it runs for every batch

**Cost Example (1000-row file):**
- Setup: 2 calls Ã— flash = $0.002
- Translation: 34 batches Ã— pro = $0.17
- **Total:** ~$0.172 (vs. $0.50 if all-pro)

---

## ğŸ“ Translation Philosophy

The Video Strategy embodies the **"Full Context Constraint Model" (å…¨è¯­å¢ƒçº¦æŸæ¨¡å¼)**:

### Core Principles

1. **Strong Contextual Anchoring**
   - Inject scene summary into every batch
   - Maintain sliding window of 5 previous rows
   - Prevents jarring context shifts

2. **Negative Constraints**
   - Blacklist beats positive rules (easier to enforce)
   - Example: "Don't use è¿›è¡Œ" vs. "Use natural verbs" (latter is vague)

3. **Dual Quality Gates**
   - **Transcription Audit:** Ensures source quality
   - **Translationese Blacklist:** Ensures target fluidity

4. **Adaptive Styling**
   - VO vs. OS requires different translation strategies
   - Style guide captures project-specific nuances

---

## ğŸ“Š Configuration Reference

### Processing Parameters

| Parameter | Value | Rationale |
|-----------|-------|-----------|
| `batch_size` | 30 | Large batches work because video has high topic continuity |
| `context_window.before` | 5 | Enough for dialogue context without excessive tokens |
| `context_window.after` | 0 | No need to look ahead (not merging cross-row) |
| `inject_full_context` | true | Critical for video - prevents topic drift |
| `full_context_max_chars` | 3000 | First ~500 rows (compressed to 500 chars) |

### Feature Flags

| Feature | Enabled | Purpose |
|---------|---------|---------|
| `generate_style_guide` | âœ… | Pre-analysis for VO/OS conventions |
| `enable_transcription_audit` | âœ… | Flag ASR errors |
| `enable_blacklist` | âœ… | Prevent Translationese |
| `cross_row_merging` | âŒ | Subtitles must maintain timing alignment |
| `enable_qa_check` | âŒ | Transcription audit is sufficient |

---

## ğŸ”„ End-to-End Example

### Input TSV
```tsv
ID	Source	Target
1	Welcome to the show!	
2	Today we're talking about AI.	
3	pay an RMB	
```

### Processing

**Row 1:**
- Style: VO (spoken)
- Blacklist: âŒ (no violations)
- Transcription: âœ… (clean)
- Output: `æ¬¢è¿æ¥åˆ°èŠ‚ç›®ï¼`

**Row 2:**
- Style: VO (spoken)
- Context: "Welcome to the show!" (previous row)
- Output: `ä»Šå¤©æˆ‘ä»¬èŠèŠäººå·¥æ™ºèƒ½ã€‚`

**Row 3:**
- Transcription: âš ï¸ Suspicious ("pay an RMB" likely "pay an arm and a leg")
- Output: `ä»˜å‡ºå·¨å¤§ä»£ä»·` (corrected translation)
- Comment: `âš ï¸ [TRANSCRIPTION FLAG]: Suspected ASR error`

### Output TSV
```tsv
ID	Source	Target	Comments
1	Welcome to the show!	æ¬¢è¿æ¥åˆ°èŠ‚ç›®ï¼	VO
2	Today we're talking about AI.	ä»Šå¤©æˆ‘ä»¬èŠèŠäººå·¥æ™ºèƒ½ã€‚	VO
3	pay an RMB	ä»˜å‡ºå·¨å¤§ä»£ä»·	âš ï¸ [TRANSCRIPTION FLAG]: Suspected ASR error - likely "pay an arm and a leg"
```

---

## ğŸš€ Usage

### CLI
```bash
# Translation mode (empty Target column)
python helper.py -i subtitles.tsv -m video

# Proofreading mode (existing Target translations)
python helper.py -i subtitles.tsv -m video
```

### Programmatic
```python
from strategies.video import VideoStrategy
from core.llm_client import LLMClient
from core.processor import Processor

config = load_yaml('config.yaml')
strategy = VideoStrategy(config)
strategy.setup('input.tsv')  # Generate scene summary + style guide

processor = Processor(config, LLMClient(config))
processor.run('input.tsv', 'output.tsv', strategy)
```

---

## ğŸ“ Key Takeaways

1. **Context is King**: Compressed scene summary provides global awareness
2. **Blacklists > Rules**: Negative constraints are easier to enforce than positive guidelines
3. **Multi-Stage Models**: Use cheap models for setup, premium for translation
4. **Quality Gates**: Transcription audit + translationese prevention = high-quality output
5. **Adaptive Styling**: VO vs. OS requires different translation philosophies

---

## ğŸ”— Related Files

- **Implementation:** `strategies/video.py`
- **Configuration:** `config.yaml` (lines 110-154)
- **Base Logic:** `strategies/base_strategy.py`
- **Processing Loop:** `core/processor.py`
- **Methodology:** `METHODOLOGY.md` (Section 3)

---

*Last Updated: 2026-01-04*  
*Author: Code Analysis by Antigravity*
